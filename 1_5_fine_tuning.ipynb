{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-5_fine_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEEIGntCtYjCDPq0BPsYYR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db6ffaebfcf74f28a2ed13b24ee76601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8230b6c6fe89488c864fba3505a76b23",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5cc41f046c54091accd291cdd25a83b",
              "IPY_MODEL_71f85b68fef34168b8f8084214f6bf1a"
            ]
          }
        },
        "8230b6c6fe89488c864fba3505a76b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5cc41f046c54091accd291cdd25a83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39090d3578614ad9b8f1f683465a98e9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db2957f0b6a24483b7d6dc067c3381be"
          }
        },
        "71f85b68fef34168b8f8084214f6bf1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_24494c705db04e5da574493c37989e1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:18&lt;00:00, 30.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_78af9a05f1db4b8981bf6f6ae40da756"
          }
        },
        "39090d3578614ad9b8f1f683465a98e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db2957f0b6a24483b7d6dc067c3381be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24494c705db04e5da574493c37989e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "78af9a05f1db4b8981bf6f6ae40da756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtaruOhto/learn_pytorch_advanced/blob/master/1_5_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31byjdvUkR00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 参照元: https://github.com/YutaroOgawa/pytorch_advanced/blob/master/1_image_classification/1-5_fine_tuning.ipynb\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import urllib\n",
        "\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0EjWuz29xtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)\n",
        "\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnW7WAXD-Ley",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5587b8c-fe6b-4838-f395-3bbd7e86211f"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "hymenoptera_url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
        "hymenoptera_zip = os.path.join(\"hymenoptera_data.zip\")\n",
        "\n",
        "if not os.path.exists(hymenoptera_zip):\n",
        "    print(\"アリとハチの画像群をダウンロード\")\n",
        "    urllib.request.urlretrieve(hymenoptera_url, hymenoptera_zip)\n",
        "\n",
        "    # ZIPファイルを読み込み\n",
        "    zip = zipfile.ZipFile(hymenoptera_zip)\n",
        "    zip.extractall(\"./\")  # ZIPを解凍\n",
        "    zip.close()  # ZIPファイルをクローズ\n",
        "\n",
        "    # ZIPファイルを消去\n",
        "    os.remove(hymenoptera_zip)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "アリとハチの画像群をダウンロード\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z_aDMXK93Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageTransform():\n",
        "\n",
        "  def __init__(self, resize, mean, std):\n",
        "    self.data_transform = {\n",
        "        \"train\": transforms.Compose([\n",
        "          transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        \"val\": transforms.Compose([\n",
        "          transforms.Resize(resize),\n",
        "          transforms.CenterCrop(resize),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean, std)\n",
        "        ])\n",
        "    }\n",
        "  \n",
        "  def __call__(self, img, phase=\"train\"):\n",
        "    return self.data_transform[phase](img)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfrGTRDTIZ2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7bdc77cd-c9e3-424b-d6c6-10dbb23d6618"
      },
      "source": [
        "def make_datapath_list(phase=\"train\"):\n",
        "  rootpath = \"./hymenoptera_data/\"\n",
        "  target_path = os.path.join(rootpath + phase + \"/**/*.jpg\")\n",
        "  print(target_path)\n",
        "\n",
        "  path_list = []\n",
        "\n",
        "  # globを利用してサブディレクトリまでファイルパスを取得する\n",
        "  for path in glob.glob(target_path):\n",
        "    path_list.append(path)\n",
        "  return path_list\n",
        "\n",
        "train_list = make_datapath_list(phase=\"train\")\n",
        "val_list = make_datapath_list(phase=\"val\")\n",
        "\n",
        "train_list[:20]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./hymenoptera_data/train/**/*.jpg\n",
            "./hymenoptera_data/val/**/*.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./hymenoptera_data/train/ants/196757565_326437f5fe.jpg',\n",
              " './hymenoptera_data/train/ants/1368913450_e146e2fb6d.jpg',\n",
              " './hymenoptera_data/train/ants/24335309_c5ea483bb8.jpg',\n",
              " './hymenoptera_data/train/ants/474806473_ca6caab245.jpg',\n",
              " './hymenoptera_data/train/ants/150801171_cd86f17ed8.jpg',\n",
              " './hymenoptera_data/train/ants/VietnameseAntMimicSpider.jpg',\n",
              " './hymenoptera_data/train/ants/2019439677_2db655d361.jpg',\n",
              " './hymenoptera_data/train/ants/522163566_fec115ca66.jpg',\n",
              " './hymenoptera_data/train/ants/245647475_9523dfd13e.jpg',\n",
              " './hymenoptera_data/train/ants/384191229_5779cf591b.jpg',\n",
              " './hymenoptera_data/train/ants/450057712_771b3bfc91.jpg',\n",
              " './hymenoptera_data/train/ants/662541407_ff8db781e7.jpg',\n",
              " './hymenoptera_data/train/ants/535522953_308353a07c.jpg',\n",
              " './hymenoptera_data/train/ants/403746349_71384f5b58.jpg',\n",
              " './hymenoptera_data/train/ants/army-ants-red-picture.jpg',\n",
              " './hymenoptera_data/train/ants/386190770_672743c9a7.jpg',\n",
              " './hymenoptera_data/train/ants/822537660_caf4ba5514.jpg',\n",
              " './hymenoptera_data/train/ants/154124431_65460430f2.jpg',\n",
              " './hymenoptera_data/train/ants/684133190_35b62c0c1d.jpg',\n",
              " './hymenoptera_data/train/ants/460372577_f2f6a8c9fc.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tq3m2GLJlyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "294141aa-7e27-4045-fc2b-7490013424cd"
      },
      "source": [
        "class HymenopteraDataset(data.Dataset):\n",
        "\n",
        "  def __init__(self, file_list, transform=None, phase=\"train\"):\n",
        "    self.file_list = file_list\n",
        "    self.transform = transform\n",
        "    self.phase = phase\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.file_list)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_path = self.file_list[index]\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    img_transformed = self.transform(img, self.phase)\n",
        "\n",
        "    if \"/ants/\" in img_path:\n",
        "      label = 0\n",
        "    elif \"/bees/\" in img_path:\n",
        "      label = 1\n",
        "    \n",
        "    return img_transformed, label\n",
        "  \n",
        "train_dataset = HymenopteraDataset(file_list=train_list, transform=ImageTransform(size, mean, std), phase=\"train\")\n",
        "\n",
        "val_dataset = HymenopteraDataset(file_list=val_list, transform=ImageTransform(size, mean, std), phase=\"val\")\n",
        "\n",
        "index = 0\n",
        "print(train_dataset.__getitem__(index)[0].size())\n",
        "print(train_dataset.__getitem__(index)[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L1Ph8MBMQmj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "75ffb636-5ae4-4953-e7f1-810d2c016bfe"
      },
      "source": [
        "train_list = make_datapath_list(phase=\"train\")\n",
        "val_list = make_datapath_list(phase=\"val\")\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./hymenoptera_data/train/**/*.jpg\n",
            "./hymenoptera_data/val/**/*.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE_mgDLIQzE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848,
          "referenced_widgets": [
            "db6ffaebfcf74f28a2ed13b24ee76601",
            "8230b6c6fe89488c864fba3505a76b23",
            "b5cc41f046c54091accd291cdd25a83b",
            "71f85b68fef34168b8f8084214f6bf1a",
            "39090d3578614ad9b8f1f683465a98e9",
            "db2957f0b6a24483b7d6dc067c3381be",
            "24494c705db04e5da574493c37989e1e",
            "78af9a05f1db4b8981bf6f6ae40da756"
          ]
        },
        "outputId": "73848961-0e5e-491e-d24e-40b2d2cbd820"
      },
      "source": [
        "use_pretrained = True\n",
        "net = models.vgg16(pretrained=use_pretrained)\n",
        "\n",
        "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
        "\n",
        "net.train()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db6ffaebfcf74f28a2ed13b24ee76601",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp5rT26wSCt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 損失関数を設定する\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOxRFFwwSHkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "f00c3a1a-ad4d-4ad7-a17f-bc60d267fa7a"
      },
      "source": [
        "params_to_update_1 = []\n",
        "params_to_update_2 = []\n",
        "params_to_update_3 = []\n",
        "\n",
        "update_param_names_1 = [\"features\"]\n",
        "update_param_names_2 = [\"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n",
        "update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
        "\n",
        "for name, param in net.named_parameters():\n",
        "  if update_param_names_1[0] in name:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_1.append(param)\n",
        "    print(\"params_to_update_1に格納:\", name)\n",
        "\n",
        "  elif name in update_param_names_2:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_2.append(param)\n",
        "    print(\"params_to_update_2に格納:\", name)\n",
        "\n",
        "  elif name in update_param_names_3:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_3.append(param)\n",
        "    print(\"params_to_update_3に格納\", name)\n",
        "\n",
        "  else:\n",
        "    param.requires_grad = False\n",
        "    print(\"勾配計算なし。学習せず\", name)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params_to_update_1に格納: features.0.weight\n",
            "params_to_update_1に格納: features.0.bias\n",
            "params_to_update_1に格納: features.2.weight\n",
            "params_to_update_1に格納: features.2.bias\n",
            "params_to_update_1に格納: features.5.weight\n",
            "params_to_update_1に格納: features.5.bias\n",
            "params_to_update_1に格納: features.7.weight\n",
            "params_to_update_1に格納: features.7.bias\n",
            "params_to_update_1に格納: features.10.weight\n",
            "params_to_update_1に格納: features.10.bias\n",
            "params_to_update_1に格納: features.12.weight\n",
            "params_to_update_1に格納: features.12.bias\n",
            "params_to_update_1に格納: features.14.weight\n",
            "params_to_update_1に格納: features.14.bias\n",
            "params_to_update_1に格納: features.17.weight\n",
            "params_to_update_1に格納: features.17.bias\n",
            "params_to_update_1に格納: features.19.weight\n",
            "params_to_update_1に格納: features.19.bias\n",
            "params_to_update_1に格納: features.21.weight\n",
            "params_to_update_1に格納: features.21.bias\n",
            "params_to_update_1に格納: features.24.weight\n",
            "params_to_update_1に格納: features.24.bias\n",
            "params_to_update_1に格納: features.26.weight\n",
            "params_to_update_1に格納: features.26.bias\n",
            "params_to_update_1に格納: features.28.weight\n",
            "params_to_update_1に格納: features.28.bias\n",
            "params_to_update_2に格納: classifier.0.weight\n",
            "params_to_update_2に格納: classifier.0.bias\n",
            "params_to_update_2に格納: classifier.3.weight\n",
            "params_to_update_2に格納: classifier.3.bias\n",
            "params_to_update_3に格納 classifier.6.weight\n",
            "params_to_update_3に格納 classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJO8zSX_UbLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD([\n",
        "  {\"params\": params_to_update_1, \"lr\": 1e-4},\n",
        "  {\"params\": params_to_update_2, \"lr\": 5e-4},\n",
        "  {\"params\": params_to_update_3, \"lr\": 1e-3}\n",
        "], momentum=0.9)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u6eo_dWVkAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"{device}を使います。\")\n",
        "\n",
        "  # ネットワークをGPUに送信\n",
        "  net.to(device)\n",
        "\n",
        "  # ネットワークがある程度固定であれば、高速化させる\n",
        "  torch.backends.cudnn.benchmark = True\n",
        "\n",
        "  # epochのループ\n",
        "  for epoch in range(num_epochs):\n",
        "    print(f\"Epoch: {epoch + 1} {num_epochs}\")\n",
        "    print(\"******************\")\n",
        "\n",
        "    # epochごとの訓練と検証のループ\n",
        "    for phase in [\"train\", \"val\"]:\n",
        "      if phase == \"train\":\n",
        "        net.train() # モデルを訓練モードに\n",
        "      else:\n",
        "        net.eval() # モデルを検証モードに\n",
        "      \n",
        "      epoch_loss = 0.0 # epochの損失和\n",
        "      epoch_corrects = 0 # epochの正解数\n",
        "\n",
        "      # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
        "      if (epoch == 0) and (phase == \"train\"):\n",
        "        continue\n",
        "\n",
        "      # データローダーからミニバッチを取り出すループ\n",
        "      for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "\n",
        "        # GPUが使えるならGPUにデータを送る\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # optimizerを初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 順伝播 (forward) 計算\n",
        "        with torch.set_grad_enabled(phase == \"train\"):\n",
        "          outputs = net(inputs)\n",
        "          loss = criterion(outputs, labels) # 損失計算\n",
        "          _, preds = torch.max(outputs, 1) # ラベルを予測\n",
        "\n",
        "          # 訓練時はバックプロパゲーション\n",
        "          if phase == \"train\":\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "          epoch_loss += loss.item() * inputs.size(0) # lossの合計を更新\n",
        "          # 正解数の合計を更新\n",
        "          epoch_corrects += torch.sum(preds == labels.data)\n",
        "      epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "      epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "      print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvTvCApKZSjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f9e3cb62-be66-4b89-ec4a-ec6264a3567d"
      },
      "source": [
        "# 学習・検証を実行する\n",
        "num_epochs=2\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda:0を使います。\n",
            "Epoch: 1 2\n",
            "******************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.7704 Acc: 0.4444\n",
            "Epoch: 2 2\n",
            "******************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:10<00:00,  1.32s/it]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4775 Acc: 0.7407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.1730 Acc: 0.9542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIvvr21PZbzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = \"./weights_file_tuning.pth\"\n",
        "torch.save(net.state_dict(), model_path)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZjXf9AfaNed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6f21f4c-f41d-4e73-e54a-8449a0691e36"
      },
      "source": [
        "weights = None\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  # ケース1: GPU上で保存された重みをGPU上でロードする場合\n",
        "  load_weights = torch.load(model_path)\n",
        "  weights = net.load_state_dict(load_weights)\n",
        "else:\n",
        "  # ケース2: GPU上で保存された重みをCPU上でロードする場合\n",
        "  load_weights = torch.load(model_path, map_location={\"cuda:0\": \"cpu\"})\n",
        "  weights = net.load_state_dict(load_weights)\n",
        "  \n",
        "weights"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}