{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-5_fine_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO5YMcc/GtA7l36mGkeHFjE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtaruOhto/learn_pytorch_advanced/blob/master/1_5_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31byjdvUkR00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 参照元: https://github.com/YutaroOgawa/pytorch_advanced/blob/master/1_image_classification/1-5_fine_tuning.ipynb\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import urllib\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import models, transforms\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0EjWuz29xtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)\n",
        "\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnW7WAXD-Ley",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "417e9ed3-4f63-466a-ea5f-74ba2e541854"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "hymenoptera_url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
        "hymenoptera_zip = os.path.join(\"hymenoptera_data.zip\")\n",
        "\n",
        "if not os.path.exists(hymenoptera_zip):\n",
        "    print(\"アリとハチの画像群をダウンロード\")\n",
        "    urllib.request.urlretrieve(hymenoptera_url, hymenoptera_zip)\n",
        "\n",
        "    # ZIPファイルを読み込み\n",
        "    zip = zipfile.ZipFile(hymenoptera_zip)\n",
        "    zip.extractall(\"./\")  # ZIPを解凍\n",
        "    zip.close()  # ZIPファイルをクローズ\n",
        "\n",
        "    # ZIPファイルを消去\n",
        "    os.remove(hymenoptera_zip)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "アリとハチの画像群をダウンロード\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z_aDMXK93Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageTransform():\n",
        "\n",
        "  def __init__(self, resize, mean, std):\n",
        "    self.data_transform = {\n",
        "        \"train\": transforms.Compose([\n",
        "          transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        \"val\": transforms.Compose([\n",
        "          transforms.Resize(resize),\n",
        "          transforms.CenterCrop(resize),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean, std)\n",
        "        ])\n",
        "    }\n",
        "  \n",
        "  def __call__(self, img, phase=\"train\"):\n",
        "    return self.data_transform[phase](img)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfrGTRDTIZ2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "348864b4-fa85-4f8d-fe38-34dd0f11c876"
      },
      "source": [
        "def make_datapath_list(phase=\"train\"):\n",
        "  rootpath = \"./hymenoptera_data/\"\n",
        "  target_path = os.path.join(rootpath + phase + \"/**/*.jpg\")\n",
        "  print(target_path)\n",
        "\n",
        "  path_list = []\n",
        "\n",
        "  # globを利用してサブディレクトリまでファイルパスを取得する\n",
        "  for path in glob.glob(target_path):\n",
        "    path_list.append(path)\n",
        "  return path_list\n",
        "\n",
        "train_list = make_datapath_list(phase=\"train\")\n",
        "val_list = make_datapath_list(phase=\"val\")\n",
        "\n",
        "train_list[:20]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./hymenoptera_data/train/**/*.jpg\n",
            "./hymenoptera_data/val/**/*.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./hymenoptera_data/train/ants/196757565_326437f5fe.jpg',\n",
              " './hymenoptera_data/train/ants/1368913450_e146e2fb6d.jpg',\n",
              " './hymenoptera_data/train/ants/24335309_c5ea483bb8.jpg',\n",
              " './hymenoptera_data/train/ants/474806473_ca6caab245.jpg',\n",
              " './hymenoptera_data/train/ants/150801171_cd86f17ed8.jpg',\n",
              " './hymenoptera_data/train/ants/VietnameseAntMimicSpider.jpg',\n",
              " './hymenoptera_data/train/ants/2019439677_2db655d361.jpg',\n",
              " './hymenoptera_data/train/ants/522163566_fec115ca66.jpg',\n",
              " './hymenoptera_data/train/ants/245647475_9523dfd13e.jpg',\n",
              " './hymenoptera_data/train/ants/384191229_5779cf591b.jpg',\n",
              " './hymenoptera_data/train/ants/450057712_771b3bfc91.jpg',\n",
              " './hymenoptera_data/train/ants/662541407_ff8db781e7.jpg',\n",
              " './hymenoptera_data/train/ants/535522953_308353a07c.jpg',\n",
              " './hymenoptera_data/train/ants/403746349_71384f5b58.jpg',\n",
              " './hymenoptera_data/train/ants/army-ants-red-picture.jpg',\n",
              " './hymenoptera_data/train/ants/386190770_672743c9a7.jpg',\n",
              " './hymenoptera_data/train/ants/822537660_caf4ba5514.jpg',\n",
              " './hymenoptera_data/train/ants/154124431_65460430f2.jpg',\n",
              " './hymenoptera_data/train/ants/684133190_35b62c0c1d.jpg',\n",
              " './hymenoptera_data/train/ants/460372577_f2f6a8c9fc.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tq3m2GLJlyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d7c907a5-2a22-45d4-c7ad-9c9287b26a7f"
      },
      "source": [
        "class HymenopteraDataset(data.Dataset):\n",
        "\n",
        "  def __init__(self, file_list, transform=None, phase=\"train\"):\n",
        "    self.file_list = file_list\n",
        "    self.transform = transform\n",
        "    self.phase = phase\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.file_list)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_path = self.file_list[index]\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    img_transformed = self.transform(img, self.phase)\n",
        "\n",
        "    if \"/ants/\" in img_path:\n",
        "      label = 0\n",
        "    elif \"/bees/\" in img_path:\n",
        "      label = 1\n",
        "    \n",
        "    return img_transformed, label\n",
        "  \n",
        "train_dataset = HymenopteraDataset(file_list=train_list, transform=ImageTransform(size, mean, std), phase=\"train\")\n",
        "\n",
        "val_dataset = HymenopteraDataset(file_list=val_list, transform=ImageTransform(size, mean, std), phase=\"val\")\n",
        "\n",
        "index = 0\n",
        "print(train_dataset.__getitem__(index)[0].size())\n",
        "print(train_dataset.__getitem__(index)[1])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L1Ph8MBMQmj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2bd5e505-8c65-48b5-dfc3-a5e345d42ef7"
      },
      "source": [
        "train_list = make_datapath_list(phase=\"train\")\n",
        "val_list = make_datapath_list(phase=\"val\")\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "dataloaders_dict\n",
        "\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./hymenoptera_data/train/**/*.jpg\n",
            "./hymenoptera_data/val/**/*.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7fcae41c3860>,\n",
              " 'val': <torch.utils.data.dataloader.DataLoader at 0x7fcae41c31d0>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOxRFFwwSHkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "c105556e-294e-469c-dc99-8a0a1324fab9"
      },
      "source": [
        "use_pretrained = True\n",
        "net = models.vgg16(pretrained=use_pretrained)\n",
        "\n",
        "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
        "\n",
        "net.train()\n",
        "# 損失関数を設定する\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "params_to_update_1 = []\n",
        "params_to_update_2 = []\n",
        "params_to_update_3 = []\n",
        "\n",
        "update_param_names_1 = [\"features\"]\n",
        "update_param_names_2 = [\"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n",
        "update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
        "\n",
        "for name, param in net.named_parameters():\n",
        "  if update_param_names_1[0] in name:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_1.append(param)\n",
        "    print(\"params_to_update_1に格納:\", name)\n",
        "\n",
        "  elif name in update_param_names_2:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_2.append(param)\n",
        "    print(\"params_to_update_2に格納:\", name)\n",
        "\n",
        "  elif name in update_param_names_3:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_3.append(param)\n",
        "    print(\"params_to_update_3に格納\", name)\n",
        "\n",
        "  else:\n",
        "    param.requires_grad = False\n",
        "    print(\"勾配計算なし。学習せず\", name)\n",
        "\n",
        "optimizer = optim.SGD([\n",
        "  {\"params\": params_to_update_1, \"lr\": 1e-4},\n",
        "  {\"params\": params_to_update_2, \"lr\": 5e-4},\n",
        "  {\"params\": params_to_update_3, \"lr\": 1e-3}\n",
        "], momentum=0.9)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params_to_update_1に格納: features.0.weight\n",
            "params_to_update_1に格納: features.0.bias\n",
            "params_to_update_1に格納: features.2.weight\n",
            "params_to_update_1に格納: features.2.bias\n",
            "params_to_update_1に格納: features.5.weight\n",
            "params_to_update_1に格納: features.5.bias\n",
            "params_to_update_1に格納: features.7.weight\n",
            "params_to_update_1に格納: features.7.bias\n",
            "params_to_update_1に格納: features.10.weight\n",
            "params_to_update_1に格納: features.10.bias\n",
            "params_to_update_1に格納: features.12.weight\n",
            "params_to_update_1に格納: features.12.bias\n",
            "params_to_update_1に格納: features.14.weight\n",
            "params_to_update_1に格納: features.14.bias\n",
            "params_to_update_1に格納: features.17.weight\n",
            "params_to_update_1に格納: features.17.bias\n",
            "params_to_update_1に格納: features.19.weight\n",
            "params_to_update_1に格納: features.19.bias\n",
            "params_to_update_1に格納: features.21.weight\n",
            "params_to_update_1に格納: features.21.bias\n",
            "params_to_update_1に格納: features.24.weight\n",
            "params_to_update_1に格納: features.24.bias\n",
            "params_to_update_1に格納: features.26.weight\n",
            "params_to_update_1に格納: features.26.bias\n",
            "params_to_update_1に格納: features.28.weight\n",
            "params_to_update_1に格納: features.28.bias\n",
            "params_to_update_2に格納: classifier.0.weight\n",
            "params_to_update_2に格納: classifier.0.bias\n",
            "params_to_update_2に格納: classifier.3.weight\n",
            "params_to_update_2に格納: classifier.3.bias\n",
            "params_to_update_3に格納 classifier.6.weight\n",
            "params_to_update_3に格納 classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u6eo_dWVkAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "d214ed7a-4173-4bdf-cf1f-2a0d04ff33d7"
      },
      "source": [
        "losses = {\n",
        "    \"train\": {},\n",
        "    \"val\": {}\n",
        "}\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"{device}を使います。\")\n",
        "\n",
        "  # ネットワークをGPUに送信\n",
        "  net.to(device)\n",
        "\n",
        "  # ネットワークがある程度固定であれば、高速化させる\n",
        "  torch.backends.cudnn.benchmark = True\n",
        "\n",
        "  # epochのループ\n",
        "  for epoch in range(num_epochs):\n",
        "    print(f\"Epoch: {epoch} / {num_epochs}\")\n",
        "    print(\"========================================\")\n",
        "\n",
        "    # epochごとの訓練と検証のループ\n",
        "    for phase in [\"train\", \"val\"]:\n",
        "      if phase == \"train\":\n",
        "        net.train() # モデルを訓練モードに\n",
        "      else:\n",
        "        net.eval() # モデルを検証モードに\n",
        "      \n",
        "      epoch_loss = 0.0 # epochの損失和\n",
        "      epoch_corrects = 0 # epochの正解数\n",
        "\n",
        "      # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
        "      if (epoch == 0) and (phase == \"train\"):\n",
        "        continue\n",
        "\n",
        "      # データローダーからミニバッチを取り出すループ\n",
        "      for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "\n",
        "        # GPUが使えるならGPUにデータを送る\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # optimizerを初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 順伝播 (forward) 計算\n",
        "        with torch.set_grad_enabled(phase == \"train\"):\n",
        "          outputs = net(inputs)\n",
        "          loss = criterion(outputs, labels) # 損失計算\n",
        "          _, preds = torch.max(outputs, 1) # ラベルを予測\n",
        "\n",
        "          # 訓練時はバックプロパゲーション\n",
        "          if phase == \"train\":\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "          epoch_loss += loss.item() * inputs.size(0) # lossの合計を更新\n",
        "          # 正解数の合計を更新\n",
        "          epoch_corrects += torch.sum(preds == labels.data)\n",
        "      epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "      epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "      print(f\"モード: {phase}, 誤差: {epoch_loss:.4f}, 正解率: {epoch_acc:.4f}\")\n",
        "      losses[phase][epoch] = epoch_loss\n",
        "      \n",
        "# 学習・検証を実行する\n",
        "num_epochs=5\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n",
        "losses\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cuda:0を使います。\n",
            "Epoch: 0 / 5\n",
            "========================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.52it/s]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "モード: val, 誤差: 0.6646, 正解率: 0.5817\n",
            "Epoch: 1 / 5\n",
            "========================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:05<00:00,  1.60it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "モード: train, 誤差: 0.4356, 正解率: 0.7984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.65it/s]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "モード: val, 誤差: 0.1682, 正解率: 0.9477\n",
            "Epoch: 2 / 5\n",
            "========================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:04<00:00,  1.61it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "モード: train, 誤差: 0.1474, 正解率: 0.9424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.66it/s]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "モード: val, 誤差: 0.1203, 正解率: 0.9542\n",
            "Epoch: 3 / 5\n",
            "========================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:04<00:00,  1.61it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "モード: train, 誤差: 0.0795, 正解率: 0.9794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.66it/s]\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "モード: val, 誤差: 0.1150, 正解率: 0.9542\n",
            "Epoch: 4 / 5\n",
            "========================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:05<00:00,  1.59it/s]\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "モード: train, 誤差: 0.1010, 正解率: 0.9671\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:01<00:00,  2.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "モード: val, 誤差: 0.1128, 正解率: 0.9477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {1: 0.4355782743221448,\n",
              "  2: 0.14742994814375301,\n",
              "  3: 0.07947315401378482,\n",
              "  4: 0.10099742583041328},\n",
              " 'val': {0: 0.664601054066926,\n",
              "  1: 0.1682475321238337,\n",
              "  2: 0.12032910877096108,\n",
              "  3: 0.11495450663751637,\n",
              "  4: 0.112845118431484}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTJts66-zs1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "de910bf8-d3fd-4556-d7fe-7f12ce13eb30"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "x = np.arange(num_epochs)\n",
        "train_losses  = np.insert(np.array(list(losses[\"train\"].values())), 0, 1)\n",
        "val_losses = np.array(list(losses[\"val\"].values()))\n",
        "\n",
        "plt.plot(x, train_losses, label=\"train\")\n",
        "plt.plot(x, val_losses, label=\"val\")\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcae1337c18>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIvvr21PZbzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = \"./weights_file_tuning.pth\"\n",
        "torch.save(net.state_dict(), model_path)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZjXf9AfaNed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "117f19d3-8dd9-4dc5-bc66-80ca33600bd3"
      },
      "source": [
        "weights = None\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  # ケース1: GPU上で保存された重みをGPU上でロードする場合\n",
        "  load_weights = torch.load(model_path)\n",
        "  weights = net.load_state_dict(load_weights)\n",
        "else:\n",
        "  # ケース2: GPU上で保存された重みをCPU上でロードする場合\n",
        "  load_weights = torch.load(model_path, map_location={\"cuda:0\": \"cpu\"})\n",
        "  weights = net.load_state_dict(load_weights)\n",
        "  \n",
        "weights"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    }
  ]
}